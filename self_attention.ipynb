{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:31:32.163170Z",
     "iopub.status.busy": "2021-09-27T16:31:32.163170Z",
     "iopub.status.idle": "2021-09-27T16:31:33.490216Z",
     "shell.execute_reply": "2021-09-27T16:31:33.490216Z",
     "shell.execute_reply.started": "2021-09-27T16:31:32.163170Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:40:58.850089Z",
     "iopub.status.busy": "2021-09-27T16:40:58.850089Z",
     "iopub.status.idle": "2021-09-27T16:40:58.861087Z",
     "shell.execute_reply": "2021-09-27T16:40:58.861087Z",
     "shell.execute_reply.started": "2021-09-27T16:40:58.850089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating x\n",
    "# we are ignoring the batch dimension for this version of self-attention\n",
    "# x in this case will be: (token, embedding dimension)\n",
    "# therefor, there are 5 tokens and each token is 4 dimensions each\n",
    "x = torch.rand(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:40:59.609936Z",
     "iopub.status.busy": "2021-09-27T16:40:59.609936Z",
     "iopub.status.idle": "2021-09-27T16:40:59.616918Z",
     "shell.execute_reply": "2021-09-27T16:40:59.616918Z",
     "shell.execute_reply.started": "2021-09-27T16:40:59.609936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8311, 0.8966, 0.9652, 0.3645],\n",
       "        [0.7580, 0.4778, 0.5988, 0.4520],\n",
       "        [0.7356, 0.1954, 0.3560, 0.4245],\n",
       "        [0.8762, 0.1240, 0.9374, 0.5385],\n",
       "        [0.3336, 0.9823, 0.6054, 0.5508]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:41:17.968654Z",
     "iopub.status.busy": "2021-09-27T16:41:17.968654Z",
     "iopub.status.idle": "2021-09-27T16:41:17.982616Z",
     "shell.execute_reply": "2021-09-27T16:41:17.982616Z",
     "shell.execute_reply.started": "2021-09-27T16:41:17.968654Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating our linear layers\n",
    "# we only want the weights of this linear layer \n",
    "q_lin = nn.Linear(5, 3, bias=False)\n",
    "v_lin = nn.Linear(5, 3, bias=False)\n",
    "k_lin = nn.Linear(5, 3, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:41:25.863632Z",
     "iopub.status.busy": "2021-09-27T16:41:25.863632Z",
     "iopub.status.idle": "2021-09-27T16:41:25.872608Z",
     "shell.execute_reply": "2021-09-27T16:41:25.872608Z",
     "shell.execute_reply.started": "2021-09-27T16:41:25.863632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions: torch.Size([5, 4])\n",
      "Output dimensions: torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# next we need to grab our queries, values, and keys \n",
    "# before doing so we will make check the output dimension sizes\n",
    "print(f'Input dimensions: {x.shape}')\n",
    "print(f'Output dimensions: {q_lin(x.T).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:41:42.274447Z",
     "iopub.status.busy": "2021-09-27T16:41:42.274447Z",
     "iopub.status.idle": "2021-09-27T16:41:42.287442Z",
     "shell.execute_reply": "2021-09-27T16:41:42.287442Z",
     "shell.execute_reply.started": "2021-09-27T16:41:42.274447Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Getting Queries, Values, and Keys\n",
    "\"\"\"\n",
    "keys = k_lin(x.T)\n",
    "queries = q_lin(x.T)\n",
    "values = v_lin(x.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:42:16.406278Z",
     "iopub.status.busy": "2021-09-27T16:42:16.406278Z",
     "iopub.status.idle": "2021-09-27T16:42:16.415258Z",
     "shell.execute_reply": "2021-09-27T16:42:16.415258Z",
     "shell.execute_reply.started": "2021-09-27T16:42:16.406278Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Attention Filter\n",
    "\"\"\"\n",
    "# Now that we have gotten our keys, queries, and values. We will be applying our attention filter\n",
    "# remember, this of the filter as a photo filter. \n",
    "# the idea behind this filter is to 'filter' out what is most important or what\n",
    "# the model pays most attention to in the model\n",
    "A1 = torch.mm(queries, keys.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:42:46.726419Z",
     "iopub.status.busy": "2021-09-27T16:42:46.726419Z",
     "iopub.status.idle": "2021-09-27T16:42:46.741379Z",
     "shell.execute_reply": "2021-09-27T16:42:46.741379Z",
     "shell.execute_reply.started": "2021-09-27T16:42:46.726419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0461, -0.0809, -0.1210, -0.0057],\n",
       "         [ 0.2983,  0.1843,  0.2416,  0.1894],\n",
       "         [ 0.0242, -0.0446, -0.0475,  0.0374],\n",
       "         [ 0.0418,  0.0318, -0.0084,  0.0325]], grad_fn=<MmBackward>),\n",
       " torch.Size([4, 4]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this produces our initial filter\n",
    "# this filter is just the queries dot keys.tranpose\n",
    "A1, A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:44:00.154592Z",
     "iopub.status.busy": "2021-09-27T16:44:00.154592Z",
     "iopub.status.idle": "2021-09-27T16:44:00.162577Z",
     "shell.execute_reply": "2021-09-27T16:44:00.162577Z",
     "shell.execute_reply.started": "2021-09-27T16:44:00.154592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we will scale down by the k dimension\n",
    "scaler = torch.sqrt(torch.tensor(4.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:44:22.419957Z",
     "iopub.status.busy": "2021-09-27T16:44:22.419957Z",
     "iopub.status.idle": "2021-09-27T16:44:22.428957Z",
     "shell.execute_reply": "2021-09-27T16:44:22.428957Z",
     "shell.execute_reply.started": "2021-09-27T16:44:22.419957Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling down\n",
    "A2 = A1/scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T16:44:24.056995Z",
     "iopub.status.busy": "2021-09-27T16:44:24.056995Z",
     "iopub.status.idle": "2021-09-27T16:44:24.060985Z",
     "shell.execute_reply": "2021-09-27T16:44:24.060985Z",
     "shell.execute_reply.started": "2021-09-27T16:44:24.056995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0230, -0.0404, -0.0605, -0.0029],\n",
       "        [ 0.1491,  0.0922,  0.1208,  0.0947],\n",
       "        [ 0.0121, -0.0223, -0.0238,  0.0187],\n",
       "        [ 0.0209,  0.0159, -0.0042,  0.0162]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our scaled down filter\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:01:37.486654Z",
     "iopub.status.busy": "2021-09-27T17:01:37.486654Z",
     "iopub.status.idle": "2021-09-27T17:01:37.506601Z",
     "shell.execute_reply": "2021-09-27T17:01:37.506601Z",
     "shell.execute_reply.started": "2021-09-27T17:01:37.486654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2521, 0.2478, 0.2428, 0.2573],\n",
       "         [0.2588, 0.2445, 0.2516, 0.2451],\n",
       "         [0.2540, 0.2454, 0.2450, 0.2556],\n",
       "         [0.2522, 0.2509, 0.2459, 0.2510]], grad_fn=<SoftmaxBackward>),\n",
       " torch.Size([4, 4]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will apply Softmax to our filter\n",
    "# this will produce the softmax filter\n",
    "# we can use this softmax filter to view 'heat map'\n",
    "# The shape should be 4x4, which should relate to (token x token)\n",
    "A3 = F.softmax(A2, 1)\n",
    "A3, A3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:03:24.696261Z",
     "iopub.status.busy": "2021-09-27T17:03:24.696261Z",
     "iopub.status.idle": "2021-09-27T17:03:24.708229Z",
     "shell.execute_reply": "2021-09-27T17:03:24.708229Z",
     "shell.execute_reply.started": "2021-09-27T17:03:24.696261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.6343,  0.0544, -0.4861],\n",
       "         [-0.6419,  0.0541, -0.4920],\n",
       "         [-0.6364,  0.0542, -0.4877],\n",
       "         [-0.6354,  0.0549, -0.4872]], grad_fn=<MmBackward>),\n",
       " torch.Size([4, 3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. Filtered Value\n",
    "\"\"\"\n",
    "# Now that we have our filter, we will apply it to our input\n",
    "# although, instead of applying it directly to the input\n",
    "# we will be applying it to the values which was calculated X.T*Wv\n",
    "F = torch.mm(A3, values)\n",
    "F, F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T17:10:14.322355Z",
     "iopub.status.busy": "2021-09-27T17:10:14.322355Z",
     "iopub.status.idle": "2021-09-27T17:10:14.335320Z",
     "shell.execute_reply": "2021-09-27T17:10:14.335320Z",
     "shell.execute_reply.started": "2021-09-27T17:10:14.322355Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Modulated\n",
    "\"\"\"\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, ni, nf, emb_dim):\n",
    "        \"\"\"\n",
    "        ::param ni: input to linear layer, number of tokens\n",
    "        ::param nf: output to linear layer, this can be same as number of tokens\n",
    "        ::param emb_dim: embedding dimension per token\n",
    "        \"\"\"\n",
    "        self.q_lin = nn.Linear(ni, nf, bias=False)\n",
    "        self.v_lin = nn.Linear(ni, nf, bias=False)\n",
    "        self.k_lin = nn.Linear(ni, nf, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        ::param x: input, we are assuming no batched dimension for this input\n",
    "        \"\"\"\n",
    "        _, k = x.shape\n",
    "        scaler = torch.sqrt(torch.tensor(float(k)))\n",
    "        \n",
    "        \"\"\"\n",
    "        1. Grabbing queries, keys, and values\n",
    "        \"\"\"\n",
    "        \n",
    "        queries = self.q_lin(x.T)\n",
    "        values = self.v_lin(x.T)\n",
    "        keys = self.k_lin(x.T)\n",
    "        \n",
    "        \"\"\"\n",
    "        2. Attention Filter\n",
    "        \"\"\"\n",
    "        A1 = torch.mm(queries, keys.T)\n",
    "        A2 = A1/scaler\n",
    "        A3 = F.softmax(A2, 1)\n",
    "        \n",
    "        \"\"\"\n",
    "        3. Filtered Values\n",
    "        \"\"\"\n",
    "        F = torch.bmm(A3, values)\n",
    "        \n",
    "        # Returning both the filtered values -> This will be the input to the linear layer\n",
    "        # along with A3 which can be used as the heatmap\n",
    "        return F, A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
